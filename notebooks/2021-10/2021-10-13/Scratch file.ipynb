{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687f2ad2",
   "metadata": {},
   "source": [
    "Idea is to test out the following work flow\n",
    "\n",
    "https://github.com/openclimatefix/nowcasting_dataset/issues/213#issuecomment-942080996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ecb76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import annotations\n",
    "from typing import Optional\n",
    "from typing import Union, List\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "570695b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydantic dataset\n",
    "\n",
    "class PydanticXArrayDataSet(xr.Dataset):\n",
    "    # Adapted from https://pydantic-docs.helpmanual.io/usage/types/#classes-with-__get_validators__\n",
    "\n",
    "    __slots__ = []\n",
    "    \n",
    "    # TODO add validation\n",
    "\n",
    "    @classmethod\n",
    "    def __get_validators__(cls):\n",
    "        yield cls.validate\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, v):\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89d3c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr array and xr dataset --> to torch functions\n",
    "if not hasattr(xr.DataArray, \"torch\"):\n",
    "    @xr.register_dataarray_accessor(\"torch\")\n",
    "    class TorchAccessor:\n",
    "        def __init__(self, xarray_obj):\n",
    "            self._obj = xarray_obj\n",
    "\n",
    "        def to_tensor(self):\n",
    "            \"\"\"Convert this DataArray to a torch.Tensor\"\"\"\n",
    "            import torch\n",
    "\n",
    "            return torch.tensor(self._obj.data)\n",
    "\n",
    "        def to_named_tensor(self):\n",
    "            \"\"\"Convert this DataArray to a torch.Tensor with named dimensions\"\"\"\n",
    "            import torch\n",
    "\n",
    "            return torch.tensor(self._obj.data, names=self._obj.dims)\n",
    "\n",
    "\n",
    "if not hasattr(xr.Dataset, \"torch\"):\n",
    "    @xr.register_dataset_accessor(\"torch\")\n",
    "    class TorchAccessor:\n",
    "        def __init__(self, xdataset_obj: xr.Dataset):\n",
    "            self._obj = xdataset_obj\n",
    "\n",
    "        def to_tensor(self, dims: List[str]) -> dict:\n",
    "            \"\"\"Convert this Dataset to dictionary of torch tensors\"\"\"\n",
    "\n",
    "            torch_dict = {}\n",
    "\n",
    "            for dim in dims:\n",
    "                v = getattr(self._obj, dim)\n",
    "                if 'time' == dim:\n",
    "                    v = v.astype(np.int32)\n",
    "\n",
    "                torch_dict[dim] = v.torch.to_tensor()\n",
    "\n",
    "            return torch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b32175ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "\n",
    "def from_list_data_array_to_batch_dataset(image_data_arrays: List[xr.DataArray]) -> xr.Dataset:\n",
    "    # join a list of data arrays to a dataset byt expanding dims \n",
    "\n",
    "    image_data_arrays = [\n",
    "        convert_data_array_to_dataset(image_data_arrays[i]) for i in range(len(image_data_arrays))\n",
    "    ]\n",
    "\n",
    "    image_data_arrays = [\n",
    "        image_data_arrays[i].expand_dims(dim=\"example\").assign_coords(example=(\"example\", [i]))\n",
    "        for i in range(len(image_data_arrays))\n",
    "    ]\n",
    "\n",
    "    return xr.concat(image_data_arrays, dim=\"example\")\n",
    "\n",
    "\n",
    "def convert_data_array_to_dataset(data_xarray):\n",
    "    #Â convert data array to dataset, and re index dims\n",
    "\n",
    "    dims = data_xarray.dims\n",
    "    data = xr.Dataset({\"data\": data_xarray})\n",
    "\n",
    "    for dim in dims:\n",
    "        coord = data[dim]\n",
    "        data[dim] = np.arange(len(coord))\n",
    "\n",
    "        data = data.rename({dim: f\"{dim}_index\"})\n",
    "\n",
    "        data[dim] = xr.DataArray(coord, coords=data[f\"{dim}_index\"].coords, dims=[f\"{dim}_index\"])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98092ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake image xr array function\n",
    "def create_image_array(dims=(\"time\", \"x\", \"y\", \"channels\")):\n",
    "    ALL_COORDS = {\n",
    "        \"time\": pd.date_range(\"2021-01-01\", freq=\"5T\", periods=4),\n",
    "        \"x\": np.random.randint(low=0, high=1000, size=8),\n",
    "        \"y\": np.random.randint(low=0, high=1000, size=8),\n",
    "        \"channels\": np.arange(5),\n",
    "    }\n",
    "    coords = [(dim, ALL_COORDS[dim]) for dim in dims]\n",
    "    image_data_array = xr.DataArray(0, coords=coords)  # Fake data for testing!\n",
    "    return image_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50936b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define satellite models. \n",
    "# 1. xr.Dataset\n",
    "# 2. Pydantic model\n",
    "\n",
    "class Satellite(PydanticXArrayDataSet):\n",
    "    # Use to store xr.Dataset data\n",
    "    __slots__ = []\n",
    "    \n",
    "    # todo add validation here\n",
    "    \n",
    "class SatelliteML(BaseModel):\n",
    "    # Use to store data ready for ml\n",
    "    data: torch.Tensor\n",
    "    time: torch.Tensor\n",
    "    x: torch.Tensor\n",
    "    y: torch.Tensor\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40e100d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up batch models\n",
    "\n",
    "class Batch(BaseModel):\n",
    "    \"\"\"A batch of xr.Datasets.\"\"\"\n",
    "\n",
    "    satellite: Optional[Satellite]\n",
    "    # nwp\n",
    "    # metadata\n",
    "\n",
    "    def to_tensor(self):\n",
    "        # loop through data_sources, and change to tensors\n",
    "        pass\n",
    "\n",
    "    def save_netcdf(self):\n",
    "        # save to netcdf\n",
    "        self.satellite.to_netcdf('test.nc')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_netcdf():\n",
    "        # load to netcdf\n",
    "        return Batch(satellite=xr.load_dataset('test.nc'))\n",
    "        \n",
    "\n",
    "    \n",
    "class BatchML(BaseModel):\n",
    "    \"\"\"A batch machine learning training examples.\"\"\"\n",
    "\n",
    "    satellite: Optional[SatelliteML]\n",
    "    # nwp\n",
    "    # metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be2e4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow 1., create the data and save to netcdf file\n",
    "sat_1 = create_image_array()\n",
    "sat_2 = create_image_array()\n",
    "\n",
    "satellite_batch = Satellite(from_list_data_array_to_batch_dataset([sat_1, sat_2]))\n",
    "\n",
    "batch = Batch(satellite=satellite_batch)\n",
    "\n",
    "batch.save_netcdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df5c9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow 2., load data and \n",
    "batch = Batch.load_netcdf()\n",
    "\n",
    "# change to torch\n",
    "satellite_batch_ml = batch.satellite.torch.to_tensor(['data','time','x','y'])\n",
    "satellite_batch_ml = SatelliteML(**satellite_batch_ml)\n",
    "\n",
    "\n",
    "batch_ml = BatchML(satellite=satellite_batch_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ada54489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset, \n",
    "\n",
    "class FakeDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, length: int = 10):\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of pieces of data\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def per_worker_init(self, worker_id: int):\n",
    "        \"\"\"Not needed\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        batch = Batch.load_netcdf()\n",
    "\n",
    "        # change to torch\n",
    "        satellite_batch_ml = batch.satellite.torch.to_tensor(['data','time','x','y'])\n",
    "        satellite_batch_ml = SatelliteML(**satellite_batch_ml)\n",
    "\n",
    "        batch_ml = BatchML(satellite=satellite_batch_ml)\n",
    "        \n",
    "        return batch_ml.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fdb7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01802206039428711\n",
      "0.014360666275024414\n",
      "0.012000083923339844\n",
      "0.012310028076171875\n",
      "0.011492729187011719\n",
      "0.01065683364868164\n",
      "0.012231826782226562\n",
      "0.011026144027709961\n",
      "0.010531187057495117\n",
      "0.011240243911743164\n"
     ]
    }
   ],
   "source": [
    "# run dataloader\n",
    "\n",
    "train = torch.utils.data.DataLoader(FakeDataset())\n",
    "i = iter(train)\n",
    "\n",
    "for _ in range(10):\n",
    "    t =time.time()\n",
    "    x = next(i)\n",
    "    x = BatchML(**x)\n",
    "\n",
    "    print(time.time() - t)\n",
    "\n",
    "# IT WORKS\n",
    "assert type(x.satellite.data) == torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecae789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58700f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
