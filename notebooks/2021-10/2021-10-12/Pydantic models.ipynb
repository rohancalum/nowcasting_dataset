{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a31991",
   "metadata": {},
   "source": [
    "The idea with the notebook is to explore the pydantic models of the data strcuture. Some cells are there just for an example. \n",
    "\n",
    "The general aim is to remove any to_numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab02303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Pydantic Data Array and Data set. No validation is done here, but we could add some\n",
    "class PydanticXArrayDataArray(xr.DataArray):\n",
    "    # Adapted from https://pydantic-docs.helpmanual.io/usage/types/#classes-with-__get_validators__\n",
    "\n",
    "    __slots__ = []\n",
    "\n",
    "    @classmethod\n",
    "    def __get_validators__(cls):\n",
    "        yield cls.validate\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, v):\n",
    "        return v\n",
    "\n",
    "\n",
    "class PydanticXArrayDataSet(xr.Dataset):\n",
    "    # Adapted from https://pydantic-docs.helpmanual.io/usage/types/#classes-with-__get_validators__\n",
    "\n",
    "    __slots__ = []\n",
    "\n",
    "    @classmethod\n",
    "    def __get_validators__(cls):\n",
    "        yield cls.validate\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, v):\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfebf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define a general data source that stores batch dataset information\n",
    "\n",
    "class BatchDataSource(BaseModel):\n",
    "    \"\"\"Superclass for image data (satellite imagery, NWPs, etc.)\"\"\"\n",
    "\n",
    "    data: PydanticXArrayDataSet\n",
    "\n",
    "    def to_netcdf(self):\n",
    "        pass\n",
    "\n",
    "    def from_netcdf(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions\n",
    "def convert_data_array_to_dataset(data):\n",
    "\n",
    "    dims = data.dims\n",
    "    data = xr.Dataset({'data': data})\n",
    "\n",
    "    for dim in dims:\n",
    "        coord = data[dim]\n",
    "        data[dim] = np.arange(len(coord))\n",
    "\n",
    "        data[f\"{dim}_coords\"] = xr.DataArray(coord, coords=[data[dim]], dims=[dim])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def from_list_data_array_to_dataset(image_data_arrays: List[xr.DataArray]) -> xr.Dataset:\n",
    "    # might need to example dims here\n",
    "\n",
    "    image_data_arrays = [convert_data_array_to_dataset(image_data_arrays[i])\n",
    "                         for i in range(len(image_data_arrays))]\n",
    "\n",
    "    image_data_arrays = [image_data_arrays[i].expand_dims(dim='example').assign_coords(example=(\"example\", [i]))\n",
    "                         for i in range(len(image_data_arrays))]\n",
    "\n",
    "    return xr.concat(image_data_arrays, dim=\"example\")\n",
    "\n",
    "\n",
    "def create_image_array(dims=(\"time\", \"x\", \"y\", \"channels\")):\n",
    "    ALL_COORDS = {\n",
    "        \"time\": pd.date_range(\"2021-01-01\", freq=\"5T\", periods=4),\n",
    "        \"x\": np.random.randint(low=0, high=1000, size=8),\n",
    "        \"y\": np.random.randint(low=0, high=1000, size=8),\n",
    "        \"channels\": np.arange(5),\n",
    "    }\n",
    "    coords = [(dim, ALL_COORDS[dim]) for dim in dims]\n",
    "    image_data_array = xr.DataArray(0, coords=coords)  # Fake data for testing!\n",
    "    return image_data_array\n",
    "\n",
    "def create_image_dataset(dims=(\"time\", \"x\", \"y\", \"channels\")):\n",
    "    data = create_image_array(dims=dims)\n",
    "\n",
    "    return convert_data_array_to_dataset(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define the satellite modelts\n",
    "\n",
    "class Satellite(BaseModel):\n",
    "    data: PydanticXArrayDataArray\n",
    "    # can validate here satellite data\n",
    "    \n",
    "    def fake()\n",
    "        # this could be in testing folder\n",
    "        pass\n",
    "\n",
    "\n",
    "class BatchSatellite(BatchDataSource):\n",
    "    data: PydanticXArrayDataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f671cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Batch class\n",
    "\n",
    "class Batch(BaseModel):\n",
    "\n",
    "    batch_size: int = Field(\n",
    "        ...,\n",
    "        g=0,\n",
    "        description=\"The size of this batch. If the batch size is 0, \"\n",
    "        \"then this item stores one data item\",\n",
    "    )\n",
    "\n",
    "    satellite: BatchSatellite\n",
    "    nwp ....\n",
    "    pv ...\n",
    "    gsp ...\n",
    "    metadata\n",
    "        \n",
    "    def from_netcdf(self, ...):\n",
    "    # loop through data_sources, and load netcdf\n",
    "        pass\n",
    "\n",
    "\n",
    "    def to_tensor(self):\n",
    "        # loop through data_sources, and change to tensors\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some test satellite data\n",
    "\n",
    "sat_1 = Satellite(data=create_image_array())\n",
    "sat_2 = Satellite(data=create_image_array())\n",
    "\n",
    "\n",
    "satellite_batch = BatchSatellite(data=from_list_data_array_to_batch_dataset([sat_1.data, sat_2.data]))\n",
    "\n",
    "# 'satellite_batch' can be then saved to a netcdf file\n",
    "satellite_batch.to_netcdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b839493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then load the batch from all the the differetn data sources\n",
    "batch = Batch.from_netcdf(path)\n",
    "\n",
    "# in the data laoder torch.utils.data.Dataset can then return\n",
    "batch.to_tensor()\n",
    "return batch.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadf39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might want a function to split the Batch into a List[Example] and maybe a function that joins Examples to a Batch\n",
    "class Example(BaseModel):\n",
    "\n",
    "    satellite: Satellite\n",
    "    nwp ....\n",
    "    pv ...\n",
    "    gsp ...\n",
    "    metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
